{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05f6080",
   "metadata": {},
   "source": [
    "# Phase3\n",
    "## Aliasghar Pourghani\n",
    "## Saba Nasiri\n",
    "## Dariush Ghaemi\n",
    "## Part 1: Multimodal models with image and text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a650cc29",
   "metadata": {},
   "source": [
    "### Subpart 1: Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a810a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from yoloface import face_analysis\n",
    "import numpy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import ast\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9335e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def stop_word_remover(sent):\n",
    "    filtered_sentence = []\n",
    "    sent = sent.split(' ')\n",
    "    for w in sent:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    \n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb629c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_train = TfidfVectorizer()\n",
    "vectorizer_test = TfidfVectorizer()\n",
    "\n",
    "\n",
    "# Reading input data\n",
    "\n",
    "english_train_add = \"./MSCTD_dataset/english_train.txt\"\n",
    "english_test_add = \"./MSCTD_dataset/english_test.txt\"\n",
    "\n",
    "sentiment_train_add = \"./MSCTD_dataset/sentiment_train.txt\"\n",
    "sentiment_test_add = \"./MSCTD_dataset/sentiment_test.txt\"\n",
    "\n",
    "corpus_text_train = []\n",
    "corpus_text_test = []\n",
    "\n",
    "corpus_sentiment_train = []\n",
    "corpus_sentiment_test = []\n",
    "\n",
    "#####################################################################################\n",
    "txt_file = open(english_train_add, encoding=\"utf8\")\n",
    "\n",
    "for line in txt_file:\n",
    "    \n",
    "    a = stop_word_remover(re.sub(r'[^\\w\\s]','', line.strip()).lower())\n",
    "    corpus_text_train.append(a)\n",
    "\n",
    "train_tfidf = vectorizer_train.fit_transform(corpus_text_train)\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "txt_file = open(english_test_add, encoding=\"utf8\")\n",
    "\n",
    "for line in txt_file:\n",
    "    \n",
    "    a = stop_word_remover(re.sub(r'[^\\w\\s]','', line.strip()).lower())\n",
    "    corpus_text_test.append(a)\n",
    "    \n",
    "\n",
    "test_tfidf = vectorizer_test.fit_transform(corpus_text_test)\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "txt_file = open(sentiment_train_add, encoding=\"utf8\")\n",
    "\n",
    "for line in txt_file:\n",
    "    corpus_sentiment_train.append(line.strip())\n",
    "\n",
    "txt_file.close()\n",
    "\n",
    "    \n",
    "    \n",
    "#####################################################################################\n",
    "txt_file = open(sentiment_test_add, encoding=\"utf8\")\n",
    "\n",
    "for line in txt_file:\n",
    "    corpus_sentiment_test.append(line.strip())\n",
    "    \n",
    "txt_file.close()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb3b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTCTDDatasetModulated(Dataset):    \n",
    "    def __init__(self, dataset, text, sentiment, address, transform=None, target_transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.address = address\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.text = text\n",
    "        \n",
    "        self.labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "        self.texts = [tokenizer(dataset[i][0], padding='max_length', max_length = maxl, truncation=True, return_tensors=\"pt\")['input_ids'] for i in range(len(dataset))]\n",
    "\n",
    "        \n",
    "        with open(str(sentiment+\".txt\")) as file:\n",
    "            self.sentiment_list = [int(line.rstrip()) for line in file]\n",
    "        self.sentiment_images = torch.tensor(self.sentiment_list)\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        \n",
    "        batch_texts = self.texts[idx]\n",
    "        batch_y = torch.tensor(int(self.labels[idx]))      \n",
    "        \n",
    "        self.X = self.transform(plt.imread(self.address+str(idx)+'.jpg'))   \n",
    "        self.y = self.sentiment_images[idx]\n",
    "        return (self.X, batch_texts), self.y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0826f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trainset = [[corpus_text_train[x], corpus_sentiment_train[x]] for x in range(len(corpus_sentiment_train))]\n",
    "text_testset = [[corpus_text_test[x], corpus_sentiment_test[x]] for x in range(len(corpus_sentiment_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e93c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "maxl = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85a12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((128,128))])\n",
    "\n",
    "facestrainset = MTCTDDatasetModulated(text_trainset, 'MSCTD_dataset/english_train','MSCTD_dataset/sentiment_train', \"./train_ende/\", transform)\n",
    "facestestset = MTCTDDatasetModulated(text_testset, 'MSCTD_dataset/english_test', 'MSCTD_dataset/sentiment_test', \"./test/\",transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416c99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "modultrainloader =  torch.utils.data.DataLoader(dataset=facestrainset, batch_size=batch_size,shuffle=True)\n",
    "modultestloader =  torch.utils.data.DataLoader(dataset=facestestset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bdee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DropBlock2D(nn.Module):\n",
    "    r\"\"\"Args:\n",
    "        drop_prob (float): probability of an element to be dropped.\n",
    "        block_size (int): size of the block to drop\n",
    "    Shape:\n",
    "        - Input: `(N, C, H, W)`\n",
    "        - Output: `(N, C, H, W)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, drop_prob, block_size):\n",
    "        super(DropBlock2D, self).__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        assert x.dim() == 4, \\\n",
    "            \"Expected input with 4 dimensions (bsize, channels, height, width)\"\n",
    "\n",
    "        if not self.training or self.drop_prob == 0.:\n",
    "            return x.to(device)\n",
    "        else:\n",
    "            # get gamma value\n",
    "            gamma = self._compute_gamma(x)\n",
    "\n",
    "            # sample mask\n",
    "            mask = (torch.rand(x.shape[0], *x.shape[2:]) < gamma).float().to(device)\n",
    "\n",
    "            \n",
    "            # compute block mask\n",
    "            block_mask = self._compute_block_mask(mask).to(device)\n",
    "\n",
    "            # apply block mask\n",
    "            out = x * block_mask[:, None, :, :].to(device)\n",
    "\n",
    "            # scale output\n",
    "            out = out * block_mask.numel() / block_mask.sum()\n",
    "\n",
    "            return out.to(device)\n",
    "\n",
    "    def _compute_block_mask(self, mask):\n",
    "        block_mask = F.max_pool2d(input=mask[:, None, :, :],\n",
    "                                  kernel_size=(self.block_size, self.block_size),\n",
    "                                  stride=(1, 1),\n",
    "                                  padding=self.block_size // 2)\n",
    "\n",
    "        if self.block_size % 2 == 0:\n",
    "            block_mask = block_mask[:, :, :-1, :-1]\n",
    "\n",
    "        block_mask = 1 - block_mask.squeeze(1)\n",
    "\n",
    "        return block_mask\n",
    "\n",
    "    def _compute_gamma(self, x):\n",
    "        return self.drop_prob / (self.block_size ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f52e9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        out = self.bert(inputs)\n",
    "        #output = self.relu(output)\n",
    "        output = self.fc1(out[1])\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e138f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConcatNet,self).__init__()              \n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "       \n",
    "        self.conv1 = nn.Conv2d(512,128,kernel_size = 3, padding = 'same')\n",
    "        self.batch1 = nn.BatchNorm2d(128)\n",
    "       \n",
    "       \n",
    "        self.conv2 = nn.Conv2d(128,32,kernel_size = 3, padding = 'same')\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "       \n",
    "        self.conv3 = nn.Conv2d(32,8,kernel_size = 3, padding = 'same')\n",
    "        self.batch3 = nn.BatchNorm2d(8)\n",
    "\n",
    "       \n",
    "       \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,16)\n",
    "        self.fc3 = nn.Linear(16,3)\n",
    "       \n",
    "       \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2)\n",
    "       \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "       \n",
    "    def forward(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "       \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "       \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.relu(x)\n",
    "       \n",
    "       \n",
    "\n",
    "        x = self.flatten(x)      \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a285cfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phase2_model = torch.load('bertclassifier.pth').to(device)\n",
    "phase1_model = torch.load('Part2.pth').to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e499e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_net = torch.nn.Sequential(*(list(phase2_model.children())[:-4]))\n",
    "\n",
    "image_net = torch.nn.Sequential(phase1_model[0],*(list(phase1_model[1].children())[:-5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78fa5525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatNet(\n",
       "  (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (batch1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (batch2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (batch3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase1_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e72c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (2): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54562383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "class Module_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Module_net, self).__init__()\n",
    "\n",
    "        self.text_model = text_net\n",
    "        self.image_model = image_net\n",
    "        \n",
    "        for param in self.text_model.parameters():\n",
    "            param.requires_grad = False \n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False \n",
    "        \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(800, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img, txt):\n",
    "        out_text = self.text_model(txt)\n",
    "        #print(img.shape)\n",
    "        out_img = self.image_model(img)\n",
    "        #print(out_img.shape)\n",
    "        combined_out = torch.cat((out_text[1],out_img), 1)\n",
    "        output = self.relu(combined_out)\n",
    "        output = self.fc1(combined_out)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9824b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_net = Module_net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c049ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(module_net.parameters(), lr=learning_rate, eps=1e-8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c860720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(module_dataloader, model, loss_fn, optimizer):\n",
    "    size = len(module_dataloader.dataset)\n",
    "    correct=0\n",
    "\n",
    "    for batch, (X, y) in enumerate(module_dataloader):\n",
    "        X_img = X[0].to(device)\n",
    "        X_txt = X[1].to(device)\n",
    "        y_img = y.to(device)\n",
    "\n",
    "        X_txt = X_txt.squeeze(1).to(device)\n",
    "\n",
    "        pred = model(X_img, X_txt).to(device)\n",
    "        loss = loss_fn(pred, y_img)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "def test_loop(module_dataloader, model, loss_fn):\n",
    "    size = len(module_dataloader.dataset)\n",
    "    num_batches = len(module_dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(module_dataloader):\n",
    "            print(batch)\n",
    "            X_img = X[0].to(device)\n",
    "            X_txt = X[1].to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            \n",
    "            X_txt = X_txt.squeeze(1).to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X_img, X_txt).to(device)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "898d9327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:149: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.932925  [    0/20240]\n",
      "loss: 1.807361  [ 1000/20240]\n",
      "loss: 1.004080  [ 2000/20240]\n",
      "loss: 0.261960  [ 3000/20240]\n",
      "loss: 0.735787  [ 4000/20240]\n",
      "loss: 0.173120  [ 5000/20240]\n",
      "loss: 1.570258  [ 6000/20240]\n",
      "loss: 0.247190  [ 7000/20240]\n",
      "loss: 0.212268  [ 8000/20240]\n",
      "loss: 0.848327  [ 9000/20240]\n",
      "loss: 1.644123  [10000/20240]\n",
      "loss: 1.368030  [11000/20240]\n",
      "loss: 1.095323  [12000/20240]\n",
      "loss: 0.317457  [13000/20240]\n",
      "loss: 0.796968  [14000/20240]\n",
      "loss: 0.939383  [15000/20240]\n",
      "loss: 0.724352  [16000/20240]\n",
      "loss: 0.576371  [17000/20240]\n",
      "loss: 0.229059  [18000/20240]\n",
      "loss: 0.718143  [19000/20240]\n",
      "loss: 1.052376  [20000/20240]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.982771 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print('======================================================')\n",
    "    print('epoch '+str(i))\n",
    "    \n",
    "    train_loop(modultrainloader, module_net, loss_fn, optimizer)\n",
    "    test_loop(modultestloader, module_net, loss_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e63cc3",
   "metadata": {},
   "source": [
    "### comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c08486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase1evaluation(dataset, model):\n",
    "    predicted=[]\n",
    "    real=[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            X=dataset[i][0][0].reshape(1,3,128,128)\n",
    "            y=dataset[i][1].item()\n",
    "            pred = model(X.float()).argmax()\n",
    "            predicted.append(pred)\n",
    "            real.append(y)\n",
    "    return predicted, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47bb8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pphase1, rphase1 = phase1evaluation(facestestset, phase1_model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50c2279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase2evaluation(dataset, model):\n",
    "    predicted=[]\n",
    "    real=[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            X=dataset[i][0][1]\n",
    "            y=dataset[i][1].item()\n",
    "            pred = model(X).argmax()\n",
    "            predicted.append(pred)\n",
    "            real.append(y)\n",
    "    return predicted, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dd8f88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pphase2, rphase2 = phase2evaluation(facestestset, phase2_model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "435ed84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulatedevaluation(dataset, model):\n",
    "    predicted=[]\n",
    "    real=[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            img=dataset[i][0][0].reshape(1,3,128,128)\n",
    "            txt=dataset[i][0][1]\n",
    "            y=dataset[i][1].item()\n",
    "            pred = model(img,txt).argmax()\n",
    "            predicted.append(pred)\n",
    "            real.append(y)\n",
    "    return predicted, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "75d56ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pphase3, rphase3 = modulatedevaluation(facestestset, module_net.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba8bf8",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52d50e",
   "metadata": {},
   "source": [
    "phase1 model : 40.6\n",
    "\n",
    "phase2 model : 61.4\n",
    "\n",
    "phase3 model : 53.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d72b18",
   "metadata": {},
   "source": [
    "### f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581388ef",
   "metadata": {},
   "source": [
    "#### phase1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ace7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02      1298\n",
      "           1       0.43      0.99      0.60      2163\n",
      "           2       0.00      0.00      0.00      1606\n",
      "\n",
      "    accuracy                           0.43      5067\n",
      "   macro avg       0.25      0.33      0.20      5067\n",
      "weighted avg       0.27      0.43      0.26      5067\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(rphase1, pphase1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18255ad8",
   "metadata": {},
   "source": [
    "#### phase2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0681a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.72      0.47      1298\n",
      "           1       0.71      0.42      0.53      2163\n",
      "           2       0.58      0.41      0.48      1606\n",
      "\n",
      "    accuracy                           0.49      5067\n",
      "   macro avg       0.55      0.52      0.49      5067\n",
      "weighted avg       0.58      0.49      0.50      5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rphase2, pphase2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837752af",
   "metadata": {},
   "source": [
    "#### phase3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "360ec29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.57      0.47      1298\n",
      "           1       0.66      0.54      0.59      2163\n",
      "           2       0.57      0.50      0.53      1606\n",
      "\n",
      "    accuracy                           0.54      5067\n",
      "   macro avg       0.54      0.54      0.53      5067\n",
      "weighted avg       0.56      0.54      0.54      5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rphase3, pphase3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56541b7",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5044b3",
   "metadata": {},
   "source": [
    "#### phase1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4b6d465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  10, 1288,    0],\n",
       "       [  13, 2150,    0],\n",
       "       [   7, 1599,    0]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_mat1=confusion_matrix(rphase1, pphase1, labels=[0, 1, 2])\n",
    "cf_mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0d1ff477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_mat1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cfbd4",
   "metadata": {},
   "source": [
    "#### phase2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c366d81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[936, 165, 197],\n",
       "       [966, 914, 283],\n",
       "       [750, 203, 653]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mat2=confusion_matrix(rphase2, pphase2, labels=[0, 1, 2])\n",
    "cf_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9ccda3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_mat2, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dce488",
   "metadata": {},
   "source": [
    "#### phase3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc80b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 743,  304,  251],\n",
       "       [ 641, 1176,  346],\n",
       "       [ 498,  313,  795]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mat3=confusion_matrix(rphase3, pphase3, labels=[0, 1, 2])\n",
    "cf_mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "776909fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_mat3, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aedb201",
   "metadata": {},
   "source": [
    "## Subpart2: Using SOTA pre-trained models for multimodal classification\n",
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50cfe064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import BlipConfig, BlipModel\n",
    "from transformers import BlipTextConfig, BlipTextModel\n",
    "from transformers import BlipTextConfig, BlipTextModel\n",
    "from transformers import BlipVisionConfig, BlipVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75bdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, BlipForQuestionAnswering\n",
    "\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ef490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImageCaptioningDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, text):\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.text = text\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        encoding = self.processor(images=item[0][0], text=self.text[idx], padding=\"max_length\", return_tensors=\"pt\")\n",
    "        # remove batch dimension\n",
    "        encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9fb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "\n",
    "def train_loop(dataloader, model, optimizer):\n",
    "    print(len(dataloader.dataset))\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        input_ids = batch.pop(\"input_ids\").to(device)\n",
    "        pixel_values = batch.pop(\"pixel_values\").to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                    pixel_values=pixel_values,\n",
    "                    labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        print(\"Loss:\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c70dbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch.pop(\"input_ids\").to(device)\n",
    "            pixel_values = batch.pop(\"pixel_values\").to(device)\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                    pixel_values=pixel_values,\n",
    "                    labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            print(\"Loss:\", loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eeb4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_trainset = ImageCaptioningDataset(facestrainset, processor, corpus_text_train)\n",
    "\n",
    "blip_testset = ImageCaptioningDataset(facestestset, processor, corpus_text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1334d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "blip_trainloader =  torch.utils.data.DataLoader(dataset=blip_trainset, batch_size=batch_size,shuffle=True)\n",
    "blip_testloader =  torch.utils.data.DataLoader(dataset=blip_testset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26d68363",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f06983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "epoch 0\n",
      "20240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:149: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:205.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.20 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13540\\1331609775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'======================================================'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblip_trainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblip_testloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13540\\2388094274.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, optimizer)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpixel_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pixel_values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         outputs = model(input_ids=input_ids,\n\u001b[0m\u001b[0;32m     15\u001b[0m                     \u001b[0mpixel_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                     labels=input_ids)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, pixel_values, decoder_input_ids, decoder_attention_mask, attention_mask, output_attentions, output_hidden_states, labels, return_dict)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[0mimage_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         question_embeds = self.text_encoder(\n\u001b[0m\u001b[0;32m   1218\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, is_decoder)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    776\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 )\n\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    435\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m             cross_attention_outputs = self.crossattention(\n\u001b[0m\u001b[0;32m    352\u001b[0m                 \u001b[0mattention_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     ):\n\u001b[1;32m--> 268\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    269\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\blip\\modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key_query\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.20 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('======================================================')\n",
    "    print('epoch '+str(i))\n",
    "    train_loop(blip_trainloader, model, optimizer)\n",
    "    test_loop(blip_testloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7de86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d35828",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b3192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a690aa82284a41a910a7cff9dea024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79652a02af6e49deb7d59b0e8bc367ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Salesforce/blip-image-captioning-base were not used when initializing BlipModel: ['text_decoder.bert.encoder.layer.3.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.6.attention.self.query.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.6.output.dense.bias', 'text_decoder.bert.encoder.layer.8.attention.self.value.bias', 'text_decoder.bert.encoder.layer.1.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.4.attention.self.query.weight', 'text_decoder.bert.encoder.layer.6.attention.self.key.bias', 'text_decoder.bert.encoder.layer.7.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.7.output.dense.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.10.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.10.output.dense.bias', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.attention.self.key.bias', 'text_decoder.cls.predictions.transform.dense.weight', 'text_decoder.bert.embeddings.position_embeddings.weight', 'text_decoder.bert.encoder.layer.10.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.self.value.bias', 'text_decoder.bert.encoder.layer.8.output.dense.bias', 'text_decoder.bert.encoder.layer.4.attention.self.value.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.11.output.dense.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.7.output.dense.weight', 'text_decoder.bert.encoder.layer.0.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.9.attention.self.query.weight', 'text_decoder.bert.encoder.layer.5.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.attention.self.query.weight', 'text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.attention.self.key.weight', 'text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.7.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.attention.self.query.bias', 'text_decoder.bert.encoder.layer.6.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.attention.self.key.weight', 'text_decoder.bert.encoder.layer.9.attention.self.key.weight', 'text_decoder.bert.encoder.layer.2.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.self.query.bias', 'text_decoder.bert.encoder.layer.2.attention.self.value.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.9.attention.self.query.bias', 'text_decoder.bert.encoder.layer.0.attention.self.query.weight', 'text_decoder.bert.encoder.layer.5.output.dense.weight', 'text_decoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.output.dense.weight', 'text_decoder.bert.encoder.layer.2.attention.self.key.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.2.attention.self.key.bias', 'text_decoder.bert.encoder.layer.1.attention.self.value.weight', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.output.dense.bias', 'text_decoder.bert.encoder.layer.3.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.output.dense.weight', 'text_decoder.bert.encoder.layer.9.crossattention.self.key.bias', 'text_decoder.cls.predictions.decoder.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.4.attention.self.query.bias', 'text_decoder.cls.predictions.transform.LayerNorm.bias', 'text_decoder.bert.encoder.layer.1.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.0.attention.self.query.bias', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.10.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.8.attention.self.query.weight', 'text_decoder.bert.encoder.layer.8.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.7.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.6.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.attention.self.key.weight', 'text_decoder.bert.encoder.layer.7.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.6.attention.self.value.weight', 'text_decoder.bert.encoder.layer.9.output.dense.bias', 'text_decoder.bert.encoder.layer.8.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.attention.self.query.bias', 'text_decoder.bert.encoder.layer.3.attention.self.key.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.8.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.5.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.11.attention.self.key.weight', 'text_decoder.bert.encoder.layer.11.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.7.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.5.attention.self.value.weight', 'text_decoder.bert.encoder.layer.2.output.dense.bias', 'text_decoder.bert.encoder.layer.8.attention.self.key.weight', 'text_decoder.bert.encoder.layer.0.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.8.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.10.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.9.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.1.attention.self.query.weight', 'text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.attention.self.key.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.3.attention.self.value.weight', 'text_decoder.bert.encoder.layer.9.attention.self.value.bias', 'text_decoder.bert.encoder.layer.4.attention.self.key.bias', 'text_decoder.bert.encoder.layer.6.crossattention.self.value.weight', 'text_decoder.cls.predictions.decoder.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.6.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.1.attention.self.key.weight', 'text_decoder.bert.encoder.layer.5.attention.self.query.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.6.attention.self.value.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.0.output.dense.weight', 'text_decoder.bert.encoder.layer.10.attention.self.value.weight', 'text_decoder.bert.encoder.layer.8.attention.self.value.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.4.output.dense.bias', 'text_decoder.bert.encoder.layer.11.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.11.crossattention.self.key.bias', 'text_decoder.bert.embeddings.LayerNorm.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.11.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.self.key.weight', 'text_decoder.bert.encoder.layer.5.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.self.key.weight', 'text_decoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.6.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.11.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.9.attention.self.key.bias', 'text_decoder.bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.7.attention.self.value.weight', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.11.attention.self.value.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.5.output.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.1.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.9.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.11.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.attention.self.query.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.4.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.1.attention.self.query.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.8.attention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.attention.self.value.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.2.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.self.key.bias', 'text_decoder.bert.encoder.layer.0.attention.self.value.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.8.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.7.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.attention.self.key.weight', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.output.dense.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_decoder.cls.predictions.transform.LayerNorm.weight', 'text_decoder.bert.encoder.layer.4.attention.self.key.weight', 'text_decoder.bert.encoder.layer.2.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.4.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.2.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.10.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.9.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.1.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.6.attention.self.query.weight', 'text_decoder.bert.encoder.layer.1.attention.self.value.bias', 'text_decoder.bert.encoder.layer.11.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.9.output.dense.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.3.output.dense.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.0.attention.self.key.bias', 'text_decoder.bert.encoder.layer.6.output.dense.weight', 'text_decoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.7.attention.self.value.bias', 'text_decoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.11.attention.self.query.bias', 'text_decoder.bert.encoder.layer.4.attention.self.value.bias', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.2.output.dense.weight', 'text_decoder.cls.predictions.transform.dense.bias', 'text_decoder.bert.encoder.layer.11.attention.self.query.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.9.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.2.attention.self.value.bias', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.2.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.6.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.7.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.1.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.7.attention.self.query.weight', 'text_decoder.bert.encoder.layer.7.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.0.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.9.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.3.attention.self.value.bias', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.8.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.11.attention.self.key.bias', 'text_decoder.bert.encoder.layer.2.intermediate.dense.bias', 'text_decoder.cls.predictions.bias', 'text_decoder.bert.encoder.layer.10.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.7.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.attention.self.query.bias', 'text_decoder.bert.encoder.layer.8.output.dense.weight', 'text_decoder.bert.encoder.layer.11.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.7.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.10.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.11.attention.self.value.weight', 'text_decoder.bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.9.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.11.output.dense.weight', 'text_decoder.bert.encoder.layer.6.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.9.attention.output.dense.weight', 'text_decoder.bert.embeddings.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.intermediate.dense.bias', 'text_decoder.bert.embeddings.word_embeddings.weight', 'text_decoder.bert.encoder.layer.1.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.attention.self.key.bias', 'text_decoder.bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.9.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.0.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.6.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.10.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.0.output.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.6.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.9.attention.self.value.weight', 'text_decoder.bert.embeddings.position_ids', 'text_decoder.bert.encoder.layer.9.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.11.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.6.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.8.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.1.output.dense.weight', 'text_decoder.bert.encoder.layer.2.attention.self.query.weight', 'text_decoder.bert.encoder.layer.2.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.10.attention.self.query.bias', 'text_decoder.bert.encoder.layer.10.attention.self.value.bias', 'text_decoder.bert.encoder.layer.1.attention.self.key.bias', 'text_decoder.bert.encoder.layer.8.intermediate.dense.weight']\n",
      "- This IS expected if you are initializing BlipModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BlipModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BlipModel were not initialized from the model checkpoint at Salesforce/blip-image-captioning-base and are newly initialized: ['text_model.encoder.layer.9.crossattention.output.dense.weight', 'text_model.encoder.layer.8.crossattention.self.query.weight', 'text_model.encoder.layer.3.output.LayerNorm.weight', 'text_model.encoder.layer.5.attention.self.key.bias', 'text_model.encoder.layer.10.output.dense.bias', 'text_model.encoder.layer.10.attention.output.dense.weight', 'text_model.encoder.layer.10.output.LayerNorm.weight', 'text_model.encoder.layer.7.attention.output.dense.weight', 'text_model.encoder.layer.11.attention.self.key.bias', 'text_model.encoder.layer.1.crossattention.output.dense.weight', 'text_model.encoder.layer.1.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.8.attention.output.dense.bias', 'visual_projection.weight', 'text_model.encoder.layer.8.attention.self.value.weight', 'logit_scale', 'text_model.embeddings.position_embeddings.weight', 'text_model.encoder.layer.10.attention.output.dense.bias', 'text_model.encoder.layer.2.output.dense.weight', 'text_model.encoder.layer.1.output.dense.weight', 'text_model.encoder.layer.7.crossattention.self.query.weight', 'text_model.encoder.layer.9.attention.output.dense.weight', 'text_model.encoder.layer.10.crossattention.output.dense.weight', 'text_model.encoder.layer.4.attention.self.value.weight', 'text_model.encoder.layer.6.attention.output.dense.bias', 'text_model.encoder.layer.6.attention.self.key.weight', 'text_model.encoder.layer.9.crossattention.self.key.weight', 'text_model.encoder.layer.5.attention.self.key.weight', 'text_model.encoder.layer.10.attention.self.value.bias', 'text_model.encoder.layer.2.output.LayerNorm.weight', 'text_model.encoder.layer.8.crossattention.self.value.bias', 'text_model.encoder.layer.3.crossattention.self.query.weight', 'text_model.encoder.layer.7.attention.self.query.weight', 'text_model.encoder.layer.0.intermediate.dense.weight', 'text_model.encoder.layer.7.output.dense.weight', 'text_model.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.9.intermediate.dense.weight', 'text_model.encoder.layer.9.attention.self.query.bias', 'text_model.encoder.layer.8.intermediate.dense.weight', 'text_model.encoder.layer.7.crossattention.self.value.weight', 'text_model.encoder.layer.8.output.LayerNorm.bias', 'text_model.encoder.layer.1.crossattention.self.value.bias', 'text_model.encoder.layer.0.attention.self.query.bias', 'text_model.encoder.layer.5.attention.self.value.weight', 'text_model.encoder.layer.8.attention.self.key.weight', 'text_model.encoder.layer.10.output.dense.weight', 'text_model.encoder.layer.2.attention.output.LayerNorm.weight', 'text_model.encoder.layer.1.intermediate.dense.weight', 'text_model.encoder.layer.2.crossattention.self.query.weight', 'text_model.encoder.layer.3.output.dense.weight', 'text_model.encoder.layer.5.crossattention.self.query.bias', 'text_model.encoder.layer.9.attention.self.key.weight', 'text_model.encoder.layer.1.attention.self.value.bias', 'text_model.encoder.layer.9.attention.self.value.weight', 'text_model.encoder.layer.1.output.LayerNorm.bias', 'text_model.encoder.layer.4.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.output.LayerNorm.weight', 'text_model.encoder.layer.9.crossattention.output.dense.bias', 'text_model.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.4.crossattention.self.key.weight', 'text_model.pooler.dense.bias', 'text_model.embeddings.LayerNorm.bias', 'text_model.encoder.layer.4.output.dense.weight', 'text_model.encoder.layer.6.output.LayerNorm.bias', 'text_model.encoder.layer.9.output.dense.weight', 'text_model.encoder.layer.2.output.dense.bias', 'text_model.encoder.layer.6.crossattention.self.query.bias', 'text_model.encoder.layer.11.crossattention.output.dense.weight', 'text_model.encoder.layer.3.attention.output.LayerNorm.bias', 'text_model.encoder.layer.10.crossattention.self.key.weight', 'text_model.encoder.layer.3.attention.self.value.bias', 'text_model.encoder.layer.1.output.LayerNorm.weight', 'text_model.encoder.layer.1.attention.self.value.weight', 'text_model.encoder.layer.11.crossattention.self.value.weight', 'text_model.encoder.layer.4.intermediate.dense.bias', 'text_model.encoder.layer.6.crossattention.self.value.bias', 'text_model.encoder.layer.5.crossattention.output.dense.bias', 'text_model.encoder.layer.6.attention.self.value.weight', 'text_model.encoder.layer.10.crossattention.self.query.bias', 'text_model.encoder.layer.0.intermediate.dense.bias', 'text_model.encoder.layer.11.attention.output.dense.weight', 'text_model.encoder.layer.6.output.dense.bias', 'text_model.encoder.layer.8.output.dense.weight', 'text_model.encoder.layer.0.output.dense.weight', 'text_model.encoder.layer.7.attention.self.key.weight', 'text_model.encoder.layer.2.attention.self.value.bias', 'text_model.encoder.layer.9.attention.output.LayerNorm.bias', 'text_model.encoder.layer.11.attention.output.LayerNorm.weight', 'text_model.encoder.layer.0.output.LayerNorm.bias', 'text_model.encoder.layer.0.output.dense.bias', 'text_model.encoder.layer.8.attention.self.key.bias', 'text_model.encoder.layer.7.attention.output.LayerNorm.weight', 'text_model.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.6.crossattention.self.query.weight', 'text_model.encoder.layer.7.intermediate.dense.weight', 'text_model.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.1.attention.self.query.weight', 'text_model.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.10.attention.self.key.bias', 'text_model.encoder.layer.1.attention.output.dense.weight', 'text_model.encoder.layer.1.crossattention.output.dense.bias', 'text_model.encoder.layer.0.crossattention.output.dense.weight', 'text_model.encoder.layer.1.crossattention.self.query.bias', 'text_model.encoder.layer.9.output.dense.bias', 'text_model.encoder.layer.5.attention.self.query.bias', 'text_model.encoder.layer.10.crossattention.self.value.bias', 'text_model.encoder.layer.0.crossattention.self.query.weight', 'text_model.encoder.layer.3.intermediate.dense.bias', 'text_model.encoder.layer.1.intermediate.dense.bias', 'text_model.encoder.layer.9.attention.output.LayerNorm.weight', 'text_model.encoder.layer.3.attention.output.dense.weight', 'text_model.encoder.layer.2.crossattention.output.dense.bias', 'text_model.encoder.layer.1.attention.output.dense.bias', 'text_model.encoder.layer.2.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.output.dense.weight', 'text_model.encoder.layer.10.intermediate.dense.weight', 'text_model.encoder.layer.4.crossattention.self.query.bias', 'text_model.encoder.layer.3.attention.self.key.weight', 'text_model.encoder.layer.4.crossattention.self.query.weight', 'text_model.encoder.layer.1.crossattention.self.query.weight', 'text_model.encoder.layer.3.attention.self.query.weight', 'text_model.encoder.layer.5.output.LayerNorm.bias', 'text_model.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.5.crossattention.self.value.weight', 'text_model.encoder.layer.8.attention.self.value.bias', 'text_model.encoder.layer.9.crossattention.self.query.bias', 'text_model.encoder.layer.6.intermediate.dense.bias', 'text_model.encoder.layer.6.attention.output.LayerNorm.bias', 'text_model.encoder.layer.3.output.dense.bias', 'text_model.encoder.layer.6.attention.output.dense.weight', 'text_model.encoder.layer.0.output.LayerNorm.weight', 'text_model.encoder.layer.11.crossattention.self.key.bias', 'text_model.encoder.layer.3.crossattention.self.query.bias', 'text_model.encoder.layer.3.crossattention.output.dense.bias', 'text_model.encoder.layer.8.crossattention.self.key.bias', 'text_model.encoder.layer.4.crossattention.self.value.weight', 'text_model.encoder.layer.11.attention.self.key.weight', 'text_model.encoder.layer.6.attention.self.value.bias', 'text_model.encoder.layer.3.attention.self.query.bias', 'text_model.encoder.layer.6.output.LayerNorm.weight', 'text_model.encoder.layer.5.output.LayerNorm.weight', 'text_model.encoder.layer.7.intermediate.dense.bias', 'text_model.encoder.layer.11.intermediate.dense.weight', 'text_model.encoder.layer.0.attention.self.value.bias', 'text_model.encoder.layer.8.crossattention.output.dense.bias', 'text_model.encoder.layer.2.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.5.crossattention.self.key.bias', 'text_model.encoder.layer.6.crossattention.self.key.weight', 'text_model.encoder.layer.6.crossattention.output.dense.weight', 'text_model.encoder.layer.7.attention.output.LayerNorm.bias', 'text_model.encoder.layer.5.output.dense.weight', 'text_model.encoder.layer.10.crossattention.self.query.weight', 'text_model.encoder.layer.0.attention.output.dense.weight', 'text_model.encoder.layer.7.attention.self.value.bias', 'text_model.encoder.layer.7.output.LayerNorm.weight', 'text_model.encoder.layer.3.attention.self.value.weight', 'text_model.encoder.layer.1.crossattention.self.key.bias', 'text_model.encoder.layer.11.output.LayerNorm.weight', 'text_model.encoder.layer.11.crossattention.self.query.weight', 'text_model.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.0.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.5.intermediate.dense.bias', 'text_model.pooler.dense.weight', 'text_model.encoder.layer.0.attention.output.LayerNorm.bias', 'text_model.encoder.layer.5.attention.output.LayerNorm.weight', 'text_model.encoder.layer.10.output.LayerNorm.bias', 'text_model.encoder.layer.10.intermediate.dense.bias', 'text_model.encoder.layer.3.output.LayerNorm.bias', 'text_model.encoder.layer.7.attention.self.key.bias', 'text_model.encoder.layer.10.crossattention.self.value.weight', 'text_model.encoder.layer.11.crossattention.output.dense.bias', 'text_model.encoder.layer.4.crossattention.self.key.bias', 'text_model.encoder.layer.2.attention.self.value.weight', 'text_model.encoder.layer.3.attention.output.LayerNorm.weight', 'text_model.encoder.layer.1.output.dense.bias', 'text_model.encoder.layer.5.crossattention.self.query.weight', 'text_model.encoder.layer.2.crossattention.self.value.weight', 'text_model.encoder.layer.11.output.dense.bias', 'text_model.encoder.layer.5.attention.self.query.weight', 'text_model.encoder.layer.1.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.0.crossattention.self.key.bias', 'text_model.encoder.layer.2.intermediate.dense.bias', 'text_model.encoder.layer.2.crossattention.output.dense.weight', 'text_model.encoder.layer.2.crossattention.self.key.bias', 'text_model.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.3.crossattention.self.value.weight', 'text_model.encoder.layer.10.attention.output.LayerNorm.bias', 'text_model.encoder.layer.9.output.LayerNorm.bias', 'text_model.encoder.layer.4.crossattention.self.value.bias', 'text_projection.weight', 'text_model.encoder.layer.9.attention.self.query.weight', 'text_model.encoder.layer.9.crossattention.self.value.weight', 'text_model.encoder.layer.10.attention.self.query.weight', 'text_model.encoder.layer.0.crossattention.self.key.weight', 'text_model.encoder.layer.7.crossattention.self.key.bias', 'text_model.encoder.layer.9.output.LayerNorm.weight', 'text_model.encoder.layer.4.crossattention.output.dense.weight', 'text_model.encoder.layer.7.crossattention.self.key.weight', 'text_model.encoder.layer.7.attention.self.value.weight', 'text_model.encoder.layer.6.attention.self.query.weight', 'text_model.encoder.layer.6.intermediate.dense.weight', 'text_model.embeddings.word_embeddings.weight', 'text_model.encoder.layer.0.attention.self.query.weight', 'text_model.encoder.layer.9.attention.self.value.bias', 'text_model.encoder.layer.11.attention.self.value.weight', 'text_model.encoder.layer.8.crossattention.self.key.weight', 'text_model.encoder.layer.8.attention.output.LayerNorm.weight', 'text_model.encoder.layer.5.crossattention.self.value.bias', 'text_model.encoder.layer.0.crossattention.output.dense.bias', 'text_model.encoder.layer.3.attention.output.dense.bias', 'text_model.encoder.layer.0.attention.output.LayerNorm.weight', 'text_model.encoder.layer.3.attention.self.key.bias', 'text_model.encoder.layer.3.crossattention.output.dense.weight', 'text_model.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.4.output.LayerNorm.weight', 'text_model.encoder.layer.11.output.dense.weight', 'text_model.encoder.layer.7.crossattention.output.dense.bias', 'text_model.encoder.layer.5.output.dense.bias', 'text_model.encoder.layer.0.crossattention.self.value.bias', 'text_model.encoder.layer.6.crossattention.self.key.bias', 'text_model.encoder.layer.11.crossattention.self.value.bias', 'text_model.encoder.layer.2.intermediate.dense.weight', 'text_model.encoder.layer.3.crossattention.self.value.bias', 'text_model.encoder.layer.6.crossattention.output.dense.bias', 'text_model.encoder.layer.5.intermediate.dense.weight', 'text_model.encoder.layer.5.attention.self.value.bias', 'text_model.encoder.layer.0.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.0.attention.output.dense.bias', 'text_model.encoder.layer.1.attention.self.query.bias', 'text_model.encoder.layer.4.output.dense.bias', 'text_model.encoder.layer.7.attention.self.query.bias', 'text_model.encoder.layer.7.crossattention.output.dense.weight', 'text_model.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.2.attention.self.key.bias', 'text_model.encoder.layer.6.attention.self.key.bias', 'text_model.encoder.layer.10.attention.self.key.weight', 'text_model.encoder.layer.7.crossattention.self.query.bias', 'text_model.encoder.layer.2.attention.output.dense.bias', 'text_model.encoder.layer.9.attention.output.dense.bias', 'text_model.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.10.crossattention.output.dense.bias', 'text_model.encoder.layer.2.crossattention.self.value.bias', 'text_model.encoder.layer.11.attention.output.LayerNorm.bias', 'text_model.encoder.layer.0.attention.self.key.weight', 'text_model.encoder.layer.2.attention.self.query.bias', 'text_model.encoder.layer.0.attention.self.key.bias', 'text_model.encoder.layer.3.crossattention.self.key.weight', 'text_model.encoder.layer.2.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.self.value.bias', 'text_model.encoder.layer.11.crossattention.self.query.bias', 'text_model.encoder.layer.1.crossattention.self.value.weight', 'text_model.encoder.layer.1.attention.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.self.key.weight', 'text_model.encoder.layer.6.crossattention.self.value.weight', 'text_model.encoder.layer.8.attention.output.LayerNorm.bias', 'text_model.encoder.layer.6.attention.self.query.bias', 'text_model.encoder.layer.8.crossattention.self.value.weight', 'text_model.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.10.crossattention.self.key.bias', 'text_model.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.5.attention.output.dense.weight', 'text_model.encoder.layer.1.crossattention.self.key.weight', 'text_model.encoder.layer.8.output.dense.bias', 'text_model.encoder.layer.9.crossattention.self.key.bias', 'text_model.encoder.layer.5.attention.output.dense.bias', 'text_model.encoder.layer.11.attention.self.query.weight', 'text_model.encoder.layer.11.attention.output.dense.bias', 'text_model.encoder.layer.3.crossattention.self.key.bias', 'text_model.encoder.layer.1.attention.self.key.weight', 'text_model.encoder.layer.11.crossattention.self.key.weight', 'text_model.encoder.layer.11.attention.self.value.bias', 'text_model.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.8.crossattention.output.dense.weight', 'text_model.encoder.layer.4.attention.output.dense.bias', 'text_model.encoder.layer.6.output.dense.weight', 'text_model.encoder.layer.8.attention.output.dense.weight', 'text_model.encoder.layer.2.attention.self.key.weight', 'text_model.encoder.layer.1.attention.self.key.bias', 'text_model.encoder.layer.9.crossattention.self.query.weight', 'text_model.encoder.layer.9.crossattention.self.value.bias', 'text_model.embeddings.LayerNorm.weight', 'text_model.encoder.layer.3.intermediate.dense.weight', 'text_model.encoder.layer.8.output.LayerNorm.weight', 'text_model.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.5.crossattention.self.key.weight', 'text_model.encoder.layer.4.crossattention.output.dense.bias', 'text_model.encoder.layer.8.intermediate.dense.bias', 'text_model.encoder.layer.2.attention.output.dense.weight', 'text_model.encoder.layer.5.attention.output.LayerNorm.bias', 'text_model.encoder.layer.7.crossattention.self.value.bias', 'text_model.encoder.layer.1.attention.output.LayerNorm.weight', 'text_model.encoder.layer.5.crossattention.output.dense.weight', 'text_model.encoder.layer.8.attention.self.query.bias', 'text_model.encoder.layer.2.attention.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.self.key.bias', 'text_model.encoder.layer.6.attention.output.LayerNorm.weight', 'text_model.encoder.layer.2.crossattention.self.key.weight', 'text_model.encoder.layer.9.attention.self.key.bias', 'text_model.encoder.layer.10.attention.output.LayerNorm.weight', 'text_model.encoder.layer.4.attention.self.query.bias', 'text_model.encoder.layer.11.intermediate.dense.bias', 'text_model.encoder.layer.0.crossattention.self.value.weight', 'text_model.encoder.layer.0.crossattention.self.query.bias', 'text_model.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_model.encoder.layer.2.attention.self.query.weight', 'text_model.encoder.layer.2.crossattention.self.query.bias', 'text_model.encoder.layer.4.attention.self.query.weight', 'text_model.encoder.layer.10.attention.self.query.bias', 'text_model.encoder.layer.7.output.LayerNorm.bias', 'text_model.encoder.layer.4.attention.output.LayerNorm.bias', 'text_model.encoder.layer.4.intermediate.dense.weight', 'text_model.encoder.layer.7.attention.output.dense.bias', 'text_model.encoder.layer.8.attention.self.query.weight', 'text_model.encoder.layer.9.intermediate.dense.bias', 'text_model.encoder.layer.7.output.dense.bias', 'text_model.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_model.encoder.layer.10.attention.self.value.weight', 'text_model.encoder.layer.11.output.LayerNorm.bias', 'text_model.encoder.layer.8.crossattention.self.query.bias', 'text_model.encoder.layer.0.attention.self.value.weight', 'text_model.encoder.layer.11.attention.self.query.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20204497a5314a5ea7f08242edf3e543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab65f2375fa84ded91c77f15704dce53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13dd766a899491fbcd1584bfb528cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f196562223ef4f10a6d307dc8ea830b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import AutoProcessor, BlipModel\n",
    "\n",
    "encoder_model = BlipModel.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dc46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, text, model):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.text = text\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        inputs = self.processor(images=item[0][0].to(device), text=self.text[idx],\n",
    "                                         padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        text_embeds = outputs['image_embeds']\n",
    "        image_embeds = outputs['image_embeds']\n",
    "        y = item[1]\n",
    "        return text_embeds, image_embeds, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f3b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_encoder_trainset = EncodingDataset(facestrainset, processor, corpus_text_train, encoder_model)\n",
    "\n",
    "blip_encoder_testset = EncodingDataset(facestestset, processor, corpus_text_test, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada53634",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "blip_trainloader =  torch.utils.data.DataLoader(dataset=blip_encoder_trainset, batch_size=batch_size,shuffle=True)\n",
    "blip_testloader =  torch.utils.data.DataLoader(dataset=blip_encoder_testset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cb79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLIP_MLP(nn.Module):\n",
    "    def __init__(self, encoder_model):\n",
    "        super(BLIP_MLP,self).__init__()\n",
    "        self.encoder_model = encoder_model\n",
    "        for param in self.encoder_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        encoder_model.eval()\n",
    "        \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(1024,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.fc4 = nn.Linear(64,16)\n",
    "        self.fc5 = nn.Linear(16,3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "       \n",
    "    def forward(self,img_embeddings, txt_embeddings):\n",
    "        #print(img_embeddings.shape)\n",
    "        combined_out = torch.cat((img_embeddings,txt_embeddings), 1)\n",
    "        x = self.flatten(combined_out)      \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac78310",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_model = BLIP_MLP(encoder_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ccf83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(blip_model.parameters(), lr=learning_rate, eps=1e-8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3154a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "blip_model.train()\n",
    "blip_model = blip_model.to(device)\n",
    "\n",
    "def train_loop(dataloader, model, optimizer):\n",
    "    print(len(dataloader.dataset))\n",
    "    for idx, (txt, img, y) in enumerate(dataloader):        \n",
    "        pred = model(img, txt).to(device)\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "        if idx%100 == 0:\n",
    "            print(\"batch \"+str(idx)+\" Loss:\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def test_loop(dataloader, model):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (txt, img, y) in enumerate(dataloader):\n",
    "            \n",
    "            pred = model(img, txt).to(device)\n",
    "            loss = loss_fn(pred, y.to(device))\n",
    "            \n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7cbfc80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "epoch 0\n",
      "20240\n",
      "batch 0 Loss: 1.0687110424041748\n",
      "batch 100 Loss: 1.0626153945922852\n",
      "batch 200 Loss: 1.1831700801849365\n",
      "batch 300 Loss: 1.0615195035934448\n",
      "batch 400 Loss: 0.9464712142944336\n",
      "batch 500 Loss: 1.1752591133117676\n",
      "batch 600 Loss: 1.0698866844177246\n",
      "batch 700 Loss: 1.175132155418396\n",
      "batch 800 Loss: 1.0600223541259766\n",
      "batch 900 Loss: 0.9457628726959229\n",
      "batch 1000 Loss: 0.9459049701690674\n",
      "batch 1100 Loss: 1.1961874961853027\n",
      "batch 1200 Loss: 1.0594148635864258\n",
      "batch 1300 Loss: 1.0588722229003906\n",
      "batch 1400 Loss: 1.1858227252960205\n",
      "batch 1500 Loss: 1.0583053827285767\n",
      "batch 1600 Loss: 1.1868078708648682\n",
      "batch 1700 Loss: 1.1857842206954956\n",
      "batch 1800 Loss: 1.0721724033355713\n",
      "batch 1900 Loss: 1.1856210231781006\n",
      "batch 2000 Loss: 0.9433678984642029\n",
      "batch 2100 Loss: 1.1710764169692993\n",
      "batch 2200 Loss: 1.0562189817428589\n",
      "batch 2300 Loss: 1.0738714933395386\n",
      "batch 2400 Loss: 1.169842004776001\n",
      "batch 2500 Loss: 1.0738651752471924\n",
      "batch 2600 Loss: 1.1694175004959106\n",
      "batch 2700 Loss: 1.0730547904968262\n",
      "batch 2800 Loss: 0.941540002822876\n",
      "batch 2900 Loss: 1.169156551361084\n",
      "batch 3000 Loss: 1.1883585453033447\n",
      "batch 3100 Loss: 1.0541877746582031\n",
      "batch 3200 Loss: 1.0530903339385986\n",
      "batch 3300 Loss: 1.0743324756622314\n",
      "batch 3400 Loss: 1.211033821105957\n",
      "batch 3500 Loss: 1.0530056953430176\n",
      "batch 3600 Loss: 0.9399491548538208\n",
      "batch 3700 Loss: 1.1889543533325195\n",
      "batch 3800 Loss: 1.0756431818008423\n",
      "batch 3900 Loss: 1.0528900623321533\n",
      "batch 4000 Loss: 1.0764609575271606\n",
      "batch 4100 Loss: 1.05184006690979\n",
      "batch 4200 Loss: 0.9377825260162354\n",
      "batch 4300 Loss: 1.077229380607605\n",
      "batch 4400 Loss: 1.1916697025299072\n",
      "batch 4500 Loss: 1.2189173698425293\n",
      "batch 4600 Loss: 1.0513150691986084\n",
      "batch 4700 Loss: 1.050626277923584\n",
      "batch 4800 Loss: 1.1632273197174072\n",
      "batch 4900 Loss: 0.939145028591156\n",
      "batch 5000 Loss: 1.2152949571609497\n",
      "batch 5100 Loss: 1.1619820594787598\n",
      "batch 5200 Loss: 1.1619479656219482\n",
      "batch 5300 Loss: 1.191220760345459\n",
      "batch 5400 Loss: 1.048491358757019\n",
      "batch 5500 Loss: 1.221211314201355\n",
      "batch 5600 Loss: 0.934698224067688\n",
      "batch 5700 Loss: 1.0785936117172241\n",
      "batch 5800 Loss: 1.0480327606201172\n",
      "batch 5900 Loss: 1.0771210193634033\n",
      "batch 6000 Loss: 1.0792676210403442\n",
      "batch 6100 Loss: 1.0466628074645996\n",
      "batch 6200 Loss: 0.9331151247024536\n",
      "batch 6300 Loss: 0.9355344772338867\n",
      "batch 6400 Loss: 1.1912857294082642\n",
      "batch 6500 Loss: 1.1931405067443848\n",
      "batch 6600 Loss: 1.0477445125579834\n",
      "batch 6700 Loss: 1.0466991662979126\n",
      "batch 6800 Loss: 1.1913559436798096\n",
      "batch 6900 Loss: 1.0473817586898804\n",
      "batch 7000 Loss: 1.0465548038482666\n",
      "batch 7100 Loss: 1.0461186170578003\n",
      "batch 7200 Loss: 1.081695318222046\n",
      "batch 7300 Loss: 1.04425048828125\n",
      "batch 7400 Loss: 1.0823509693145752\n",
      "batch 7500 Loss: 1.1501195430755615\n",
      "batch 7600 Loss: 1.1507632732391357\n",
      "batch 7700 Loss: 0.9439385533332825\n",
      "batch 7800 Loss: 1.04543137550354\n",
      "batch 7900 Loss: 0.9418905973434448\n",
      "batch 8000 Loss: 0.9429587721824646\n",
      "batch 8100 Loss: 1.0459271669387817\n",
      "batch 8200 Loss: 1.1845965385437012\n",
      "batch 8300 Loss: 1.0459431409835815\n",
      "batch 8400 Loss: 1.228882074356079\n",
      "batch 8500 Loss: 1.086443543434143\n",
      "batch 8600 Loss: 1.0862805843353271\n",
      "batch 8700 Loss: 0.9404892921447754\n",
      "batch 8800 Loss: 0.9383171796798706\n",
      "batch 8900 Loss: 0.9406766891479492\n",
      "batch 9000 Loss: 1.085610032081604\n",
      "batch 9100 Loss: 0.9376372694969177\n",
      "batch 9200 Loss: 1.2339873313903809\n",
      "batch 9300 Loss: 1.2350375652313232\n",
      "batch 9400 Loss: 1.0402827262878418\n",
      "batch 9500 Loss: 1.190211534500122\n",
      "batch 9600 Loss: 1.0404882431030273\n",
      "batch 9700 Loss: 1.0383583307266235\n",
      "batch 9800 Loss: 1.143675446510315\n",
      "batch 9900 Loss: 1.1909399032592773\n",
      "batch 10000 Loss: 1.1854304075241089\n",
      "batch 10100 Loss: 1.1892210245132446\n",
      "======================================================\n",
      "epoch 1\n",
      "20240\n",
      "batch 0 Loss: 1.0382404327392578\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9412\\1306717534.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'======================================================'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblip_trainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblip_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#test_loop(blip_testloader, blip_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9412\\3713635106.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, model, optimizer)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('======================================================')\n",
    "    print('epoch '+str(i))\n",
    "    train_loop(blip_trainloader, blip_model, optimizer)\n",
    "    #test_loop(blip_testloader, blip_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc92e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(blip_trainloader, \"Method2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73dff3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 1.085744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(blip_testloader, blip_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52fee8d4",
   "metadata": {},
   "source": [
    "### Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d28282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import PerceiverModel, PerceiverConfig\n",
    "from transformers import AutoProcessor, BlipModel\n",
    "\n",
    "encoder_model = BlipModel.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "from transformers import AutoTokenizer, PerceiverForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepmind/language-perceiver\")\n",
    "model = PerceiverForMaskedLM.from_pretrained(\"deepmind/language-perceiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, dataset, processor, text, model):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.processor = processor\n",
    "        self.text = text\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        inputs = self.processor(images=item[0][0].to(device), text=self.text[idx],\n",
    "                                         padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        text_embeds = outputs['image_embeds']\n",
    "        image_embeds = outputs['image_embeds']\n",
    "        y = item[1]\n",
    "        return text_embeds, image_embeds, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_encoder_trainset = EncodingDataset(facestrainset, processor, corpus_text_train, encoder_model)\n",
    "\n",
    "perc_encoder_testset = EncodingDataset(facestestset, processor, corpus_text_test, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "perc_trainloader =  torch.utils.data.DataLoader(dataset=perc_encoder_trainset, batch_size=batch_size,shuffle=True)\n",
    "perc_testloader =  torch.utils.data.DataLoader(dataset=perc_encoder_testset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06825b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.perceiver.modeling_perceiver import PerceiverClassificationDecoder\n",
    "config = PerceiverConfig()\n",
    "config.num_labels = 3\n",
    "config.d_model = 512\n",
    "\n",
    "perceiver = PerceiverModel(\n",
    "            config=config,\n",
    "            decoder=PerceiverClassificationDecoder(\n",
    "                config,\n",
    "                num_channels=config.d_latents,\n",
    "                trainable_position_encoding_kwargs=dict(num_channels=config.d_latents, index_dims=1),\n",
    "                use_query_residual=True,)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115fc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceiver_decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, perceiver):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.perceiver = perceiver\n",
    "    \n",
    "    def forward(self, img_embeddings, txt_embeddings):\n",
    "        \n",
    "        combined_out = torch.cat((img_embeddings,txt_embeddings), dim = 1)\n",
    "        #print(combined_out.shape)\n",
    "        x = self.perceiver(combined_out).logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef52bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_classifier = Perceiver_decoder(perceiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883440a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(perc_classifier.parameters(), lr=learning_rate, eps=1e-8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "perc_classifier.train()\n",
    "\n",
    "def train_loop(dataloader, model, optimizer):\n",
    "    print(len(dataloader.dataset))\n",
    "    for idx, (txt, img, y) in enumerate(dataloader):        \n",
    "        pred = model(img, txt).to(device)\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "        if idx%100 == 0:\n",
    "            print(\"batch \"+str(idx)+\" Loss:\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "def test_loop(dataloader, model):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (txt, img, y) in enumerate(dataloader):\n",
    "            \n",
    "            pred = model(img, txt).to(device)\n",
    "            loss = loss_fn(pred, y.to(device))\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print('======================================================')\n",
    "    print('epoch '+str(i))\n",
    "    train_loop(perc_trainloader, perc_classifier, optimizer)\n",
    "    test_loop(perc_testloader, perc_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1a480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "487d99b4",
   "metadata": {},
   "source": [
    "# Part2: Multimodal Dataset for Weakly supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517211ff",
   "metadata": {},
   "source": [
    "### step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "499ff02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class unlabeledata(Dataset):    \n",
    "    def __init__(self, english_text_add, address, transform=None, target_transform=None):\n",
    "    \n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.transform = transform\n",
    "        self.address = address\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.corpus_text_train = []\n",
    "        txt_file = open(english_text_add, encoding=\"utf8\")\n",
    "        for line in txt_file:\n",
    "            a = line.strip()\n",
    "            self.corpus_text_train.append(re.sub(r'[^\\w\\s]','', a).lower())\n",
    "\n",
    "        self.texts = [tokenizer(self.corpus_text_train[i], padding='max_length', max_length = 18, truncation=True, return_tensors=\"pt\")['input_ids'] for i in range(len(self.corpus_text_train))]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus_text_train)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        self.Z = self.texts[idx]\n",
    "        self.X = self.transform(plt.imread(self.address+str(idx)+'.jpg'))   \n",
    "        return self.X, self.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfb8c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "unlabeled_image_transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128))])\n",
    "\n",
    "unlabeled_image_trainset = unlabeledata(\"./MSCTD_dataset/test.origin.txt\" ,\"./newdataset/\", unlabeled_image_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56d23cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConcatNet,self).__init__()              \n",
    "        self.pooling = nn.AvgPool2d(2)\n",
    "       \n",
    "        self.conv1 = nn.Conv2d(512,128,kernel_size = 3, padding = 'same')\n",
    "        self.batch1 = nn.BatchNorm2d(128)\n",
    "       \n",
    "       \n",
    "        self.conv2 = nn.Conv2d(128,32,kernel_size = 3, padding = 'same')\n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "       \n",
    "        self.conv3 = nn.Conv2d(32,8,kernel_size = 3, padding = 'same')\n",
    "        self.batch3 = nn.BatchNorm2d(8)\n",
    "\n",
    "       \n",
    "       \n",
    "        self.flatten = nn.Flatten()  \n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,16)\n",
    "        self.fc3 = nn.Linear(16,3)\n",
    "       \n",
    "       \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2)\n",
    "       \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "       \n",
    "    def forward(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.batch1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "       \n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "       \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.relu(x)\n",
    "       \n",
    "       \n",
    "\n",
    "        x = self.flatten(x)      \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3838a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_backbone = torch.load(\"Part2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84ba9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc1 = nn.Linear(768, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        out = self.bert(inputs)\n",
    "        output = self.fc1(out[1])\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a124ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_backbone = torch.load(\"bertclassifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625de25c",
   "metadata": {},
   "source": [
    "### step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "95931139",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_backbone.eval()\n",
    "for params in text_backbone.parameters():\n",
    "    params.requires_grad=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "711b6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in image_backbone.parameters():\n",
    "    params.requires_grad=False\n",
    "for params in image_backbone[1].fc1.parameters():\n",
    "    params.requires_grad=True\n",
    "for params in image_backbone[1].fc2.parameters():\n",
    "    params.requires_grad=True\n",
    "for params in image_backbone[1].fc3.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fd4e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): ConcatNet(\n",
       "    (pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (batch1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (batch2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (batch3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (fc3): Linear(in_features=16, out_features=3, bias=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_backbone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7889fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pseudolabeledata(Dataset):    \n",
    "    def __init__(self, data, transform=None, target_transform=None):\n",
    "    \n",
    "        self.data = data\n",
    "        self.labels = [text_backbone(data[i][1]).squeeze(0) for i in range(len(data))] \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        self.X = self.data[idx][0]   \n",
    "        self.y = self.labels[idx]\n",
    "        return self.X, self.y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea1a5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabeled_trainset = pseudolabeledata(unlabeled_image_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b265e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "batch_size =8\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98525887",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_trainloader = torch.utils.data.DataLoader(pseudolabeled_trainset, batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fd4bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50560d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(image_backbone.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3ca0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct=0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.argmax(1))\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    correct /= size\n",
    "    print(f\"Train : Accuracy between model's output and pseudo labels: {(100*correct):>0.1f}%\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8d7e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.023788  [    0/ 5147]\n",
      "loss: 1.158622  [  800/ 5147]\n",
      "loss: 0.998282  [ 1600/ 5147]\n",
      "loss: 1.091634  [ 2400/ 5147]\n",
      "loss: 1.034170  [ 3200/ 5147]\n",
      "loss: 1.112459  [ 4000/ 5147]\n",
      "loss: 1.188124  [ 4800/ 5147]\n",
      "Train : Accuracy between model's output and pseudo labels: 40.0%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.171019  [    0/ 5147]\n",
      "loss: 0.992504  [  800/ 5147]\n",
      "loss: 1.065792  [ 1600/ 5147]\n",
      "loss: 1.000763  [ 2400/ 5147]\n",
      "loss: 1.068504  [ 3200/ 5147]\n",
      "loss: 1.088071  [ 4000/ 5147]\n",
      "loss: 1.111302  [ 4800/ 5147]\n",
      "Train : Accuracy between model's output and pseudo labels: 39.6%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(2):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(unlabeled_trainloader, image_backbone, loss_fn, optimizer)\n",
    "    #test_loop(unlabeled_trainloader, image_backbone, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30afb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "class unlabeledatatest(Dataset):    \n",
    "    def __init__(self, english_text_add, address, transform=None, target_transform=None):\n",
    "    \n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.transform = transform\n",
    "        self.address = address\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.corpus_text_train = []\n",
    "        txt_file = open(english_text_add, encoding=\"utf8\")\n",
    "        for line in txt_file:\n",
    "            a = line.strip()\n",
    "            self.corpus_text_train.append(re.sub(r'[^\\w\\s]','', a).lower())\n",
    "\n",
    "        self.texts = [tokenizer(self.corpus_text_train[i], padding='max_length', max_length = 18, truncation=True, return_tensors=\"pt\")['input_ids'] for i in range(len(self.corpus_text_train))]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus_text_train)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        self.Z = self.texts[idx]\n",
    "        self.X = self.transform(plt.imread(self.address+str(idx+5147)+'.jpg'))   \n",
    "        return self.X, self.Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13e26daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "unlabeled_image_transform = transforms.Compose([transforms.ToTensor(),transforms.Resize((128,128))])\n",
    "\n",
    "unlabeled_image_testset = unlabeledatatest(\"./MSCTD_dataset/newtest.txt\" ,\"./newdatasettest/\", unlabeled_image_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42d0af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudolabeled_testset = pseudolabeledata(unlabeled_image_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d03d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_testloader = torch.utils.data.DataLoader(pseudolabeled_testset, batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "534bb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.argmax(1)).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy between model's output and pseudo labels: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3ddace4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy between model's output and pseudo labels: 43.1%, Avg loss: 1.068502 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(unlabeled_testloader, image_backbone, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2356b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(image_backbone, \"phase3_part2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ed4a1",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bacf64",
   "metadata": {},
   "source": [
    "The link of the new dataset is as follows: https://github.com/ShannonAI/OpenViDial/blob/main/datasets/README.md\n",
    "\n",
    "Further information can be obtained from the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "875431e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataset, model):\n",
    "    predicted=[]\n",
    "    real=[]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            X=dataset[i][0].reshape(1,3,128,128)\n",
    "            y=dataset[i][1].argmax()\n",
    "            pred = model(X).argmax()\n",
    "            predicted.append(pred)\n",
    "            real.append(y)\n",
    "    return predicted, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e61cba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnewdata, rnewdata = evaluation(pseudolabeled_testset, image_backbone.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c0ff9",
   "metadata": {},
   "source": [
    "#### Accuracy for Weakly supervised trained model : 43.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503ef69",
   "metadata": {},
   "source": [
    "#### f1 score for Weakly supervised trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cd110ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.02      0.04       322\n",
      "           1       0.45      0.99      0.62       452\n",
      "           2       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.45      1001\n",
      "   macro avg       0.31      0.34      0.22      1001\n",
      "weighted avg       0.35      0.45      0.29      1001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(rnewdata, pnewdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eeea7d",
   "metadata": {},
   "source": [
    "#### confusion matrix for Weakly supervised trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fd43eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7, 315,   0],\n",
       "       [  6, 446,   0],\n",
       "       [  2, 225,   0]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_mat1=confusion_matrix(rnewdata, pnewdata, labels=[0, 1, 2])\n",
    "cf_mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3b7874f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf_mat1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa359fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_model = torch.load('Part2.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5a7fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnewdata2, rnewdata2 = evaluation(pseudolabeled_testset, phase1_model.to(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e87cb038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy between model's output and pseudo labels: 43.7%, Avg loss: 1.067834 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loop(unlabeled_testloader, phase1_model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467fd5a",
   "metadata": {},
   "source": [
    "#### Accuracy for phase1 model on the new dataset : 43.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609fb5c",
   "metadata": {},
   "source": [
    "#### f1 score for phase1 model on the new dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3fe0700e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.01      0.02       322\n",
      "           1       0.45      0.99      0.62       452\n",
      "           2       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.45      1001\n",
      "   macro avg       0.27      0.33      0.21      1001\n",
      "weighted avg       0.32      0.45      0.29      1001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rnewdata2, pnewdata2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af831227",
   "metadata": {},
   "source": [
    "#### confusion matrix for phase1 model on the new dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37bbafa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4, 318,   0],\n",
       "       [  5, 447,   0],\n",
       "       [  2, 225,   0]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_mat2=confusion_matrix(rnewdata2, pnewdata2, labels=[0, 1, 2])\n",
    "cf_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97836346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cf_mat2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35794664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
